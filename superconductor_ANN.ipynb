{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "superconductor_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tajgxenyzUOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using google colab - this first step is for loading in the data from my personal Drive\n",
        "\n",
        "# Login with google credentials\n",
        "\n",
        "from pydrive.auth import GoogleAuth \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Handle errors from too many requests\n",
        "\n",
        "import logging\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n",
        "\n",
        "# The ID for my personal Drive folder is 1BVUuroPvozFxMjMIYrGOFtI4r6erSBCx\n",
        "# I am now listing the ID numbers for the files in this folder to find the data files\n",
        "\n",
        "#file_list = drive.ListFile({'q': \"'1BVUuroPvozFxMjMIYrGOFtI4r6erSBCx' in parents and trashed=false\"}).GetList()\n",
        "#for file1 in file_list:\n",
        "#  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "\n",
        "# Data ID: 1F2KojI0d-ZnN8ssQFUWSyZA8I0mAgMEf\n",
        "\n",
        "# Now that I have the ID files, load the files\n",
        "\n",
        "data_downloaded = drive.CreateFile({'id': '1dwQLnIskShTXwSeMONhu__bYFf_f8-t6'})\n",
        "data_downloaded.GetContentFile('sc_train.csv')\n",
        "\n",
        "data_downloaded = drive.CreateFile({'id': '1IcNFIYUDKz1UxFL8W_JNjz9TzjAlAOVa'})\n",
        "data_downloaded.GetContentFile('sc_unique_m.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH35BTZaz-t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data into pandas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "\n",
        "train = pd.read_csv('sc_train.csv',low_memory=False, lineterminator='\\n')\n",
        "unique = pd.read_csv('sc_unique_m.csv',low_memory=False, lineterminator='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alq4TSIg0FI_",
        "colab_type": "code",
        "outputId": "bada15f7-e352-4646-af3d-3f8563b3b3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(unique.shape)\n",
        "print(train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21263, 88)\n",
            "(21263, 82)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl3Wuu3N0X6z",
        "colab_type": "code",
        "outputId": "95ca831c-99dc-4593-f5eb-59c94b3e6cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "print(unique.head(5))\n",
        "print(train.head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     H  He   Li   Be    B  ...  Po  At  Rn  critical_temp                material\\r\n",
            "0  0.0   0  0.0  0.0  0.0  ...   0   0   0           29.0         Ba0.2La1.8Cu1O4\\r\n",
            "1  0.0   0  0.0  0.0  0.0  ...   0   0   0           26.0  Ba0.1La1.9Ag0.1Cu0.9O4\\r\n",
            "2  0.0   0  0.0  0.0  0.0  ...   0   0   0           19.0         Ba0.1La1.9Cu1O4\\r\n",
            "3  0.0   0  0.0  0.0  0.0  ...   0   0   0           22.0       Ba0.15La1.85Cu1O4\\r\n",
            "4  0.0   0  0.0  0.0  0.0  ...   0   0   0           23.0         Ba0.3La1.7Cu1O4\\r\n",
            "\n",
            "[5 rows x 88 columns]\n",
            "   number_of_elements  mean_atomic_mass  ...  wtd_std_Valence  critical_temp\\r\n",
            "0                   4         88.944468  ...         0.437059             29.0\n",
            "1                   5         92.729214  ...         0.468606             26.0\n",
            "2                   4         88.944468  ...         0.444697             19.0\n",
            "3                   4         88.944468  ...         0.440952             22.0\n",
            "4                   4         88.944468  ...         0.428809             23.0\n",
            "\n",
            "[5 rows x 82 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPj_j8_01G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge the two dataframes, drop material string\n",
        "merge_df = pd.concat([train, unique], axis=1, sort=False)\n",
        "merge_df = merge_df.drop(['material\\r'], axis=1)\n",
        "# Create feature identifying high-temp superconductors\n",
        "merge_df['is_highTc'] = merge_df['critical_temp'] > 73\n",
        "\n",
        "high_Tc_df = merge_df[merge_df['is_highTc']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqL5tbC5yxvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop outlier\n",
        "merge_df = merge_df[merge_df['critical_temp'] < 180]\n",
        "#normalize\n",
        "merge_df = (merge_df-merge_df.min())/(merge_df.max()-merge_df.min())\n",
        "# fix any NA values created by division by zero\n",
        "merge_df = merge_df.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE-rPcVMyzZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop cols with one value\n",
        "for col in merge_df.columns:\n",
        "    if len(merge_df[col].unique()) == 1:\n",
        "        merge_df.drop(col,inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWeDtbegy1Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create correlation matrix\n",
        "\n",
        "features = list(merge_df.columns.values.tolist())\n",
        "corrMat = merge_df[features].corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corrMat.where(np.triu(np.ones(corrMat.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Find index of feature columns with correlation greater than 0.95\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.5)]\n",
        "\n",
        "# make sure I don't drop my target variables\n",
        "if 'critical_temp' in to_drop: to_drop.remove('critical_temp')\n",
        "if 'is_highTc' in to_drop: to_drop.remove('is_highTc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wIvrTVdy31G",
        "colab_type": "code",
        "outputId": "36902bbb-f629-45d4-9af7-eb6ea3b32a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(to_drop)) # 55\n",
        "#to_drop\n",
        "\n",
        "merge_df = merge_df.drop(merge_df[to_drop], axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKfFY-pQy63R",
        "colab_type": "code",
        "outputId": "f6853b41-9bc6-4acc-85ba-f2c7567d6213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import seaborn as sn\n",
        "\n",
        "features = list(merge_df.columns.values.tolist())\n",
        "corrMat = merge_df[features].corr().abs()\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "#sn.heatmap(corrMat, annot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFshJAvfImdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    super(TwoLayerNet, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(D_in, H)\n",
        "    #self.leaky1 = torch.nn.LeakyReLU(H, 30)\n",
        "    self.drop1 = torch.nn.Dropout(p = 0.4)\n",
        "    self.linear2 = torch.nn.Linear(H, D_out)\n",
        "    '''\n",
        "    self.linear3 = torch.nn.Linear(H, H)\n",
        "    self.linear4 = torch.nn.Linear(H, H)\n",
        "    self.linear5 = torch.nn.Linear(H, H)\n",
        "    '''\n",
        "  def forward(self, X):\n",
        "    linear_1 = self.linear1(X)\n",
        "    #leaky_1 = self.leaky1(linear_1)\n",
        "    drop_1 = self.drop1(linear_1)\n",
        "    linear_2 = self.linear2(drop_1)\n",
        "    h_relu = linear_2.clamp(min=0)\n",
        "    \n",
        "    return h_relu\n",
        "\n",
        "def MAPELoss(output, target):\n",
        "  return 100*torch.mean(torch.abs((target - output) / (target + 0.001)))\n",
        "\n",
        "def rmse(y, y_hat):\n",
        "\n",
        "  #combined rmse value\n",
        "  mse=torch.mean((y-y_hat)**2)\n",
        "  rmse = torch.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhWX6QLu_mUj",
        "colab_type": "code",
        "outputId": "b7856c5e-a7c3-4c70-f7d2-7c890ee4500c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## train test split\n",
        "\n",
        "train_df = merge_df.sample(frac=0.8, random_state=np.random.seed())\n",
        "test_df = merge_df.drop(train_df.index)\n",
        "\n",
        "# set up train and test data\n",
        "X_train = train_df.drop(['critical_temp', 'is_highTc'], axis=1).to_numpy()\n",
        "X_test = test_df.drop(['critical_temp', 'is_highTc'], axis=1).to_numpy()\n",
        "\n",
        "X_train_high = train_df[train_df['is_highTc'] == 1].drop(['critical_temp', 'is_highTc'], axis=1).to_numpy()\n",
        "X_test_high = test_df[test_df['is_highTc'] == 1].drop(['critical_temp', 'is_highTc'], axis=1).to_numpy()\n",
        "\n",
        "# set up target variable\n",
        "y_train = train_df['critical_temp'].to_numpy()\n",
        "y_test = test_df['critical_temp'].to_numpy()\n",
        "\n",
        "# Set up alternative target - is high_T SC or not\n",
        "y_high_temp_train = train_df['is_highTc'].to_numpy()\n",
        "y_high_temp_test = test_df['is_highTc'].to_numpy()\n",
        "#convert to Torch\n",
        "\n",
        "X_torch = torch.from_numpy(X_train).float()\n",
        "X_torch_high = torch.from_numpy(X_train_high).float()\n",
        "y_torch = torch.from_numpy(y_train).float()\n",
        "y_torch_highTC = torch.from_numpy(y_high_temp_train).float()\n",
        "type(X_torch)\n",
        "\n",
        "print(sum(sum(torch.isnan(X_torch))))\n",
        "\n",
        "## No nans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSf_aR9qIwC7",
        "colab_type": "code",
        "outputId": "ea279b5d-f817-4077-a37f-59b2214f0c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_torch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2273, 0.3944, 0.4678,  ..., 0.0187, 0.6308, 0.0269])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZUvzQLAC2up",
        "colab_type": "code",
        "outputId": "b9dabe26-37ab-41d9-c191-ff891218378d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "D_in, H, D_out = X_train.shape[1], 5, 1\n",
        "print(D_in, H, D_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73 5 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYvJwGPAC8aT",
        "colab_type": "code",
        "outputId": "c90b2ae6-6103-4767-a654-0e8a282f28be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "epochs = 1000\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "    \n",
        "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "    model.cuda()\n",
        "    X_torch = X_torch.to(device)\n",
        "    y_torch = y_torch.to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(X_torch)\n",
        "    #print(X_torch)\n",
        "    #print(y_pred)\n",
        "    #print(y_torch)\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_torch)\n",
        "    if epoch % 100 == 0: \n",
        "      print(epoch, loss.item(), rmse(y_pred, y_torch))\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([17010])) that is different to the input size (torch.Size([17010, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.11578492075204849 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "100 0.11579353362321854 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "200 0.11579088866710663 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "300 0.1157890111207962 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "400 0.11579207330942154 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "500 0.1157846599817276 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "600 0.11579275131225586 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "700 0.115787073969841 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "800 0.11578858643770218 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "900 0.11579195410013199 tensor(0.3403, device='cuda:0', grad_fn=<SqrtBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdktQe3s0vg7",
        "colab_type": "code",
        "outputId": "c55101cc-8299-445a-b566-b488a07b5b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "y_pred*185"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]], device='cuda:0', grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoSK3v6xBWKs",
        "colab_type": "code",
        "outputId": "a78b075e-f7a3-44e9-9cb9-93d695960d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "epochs = 1000\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "    print(\"Using GPU!\")\n",
        "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "    model.cuda()\n",
        "    X_torch_high = X_torch_high.to(device)\n",
        "    y_torch_highTC = y_torch_highTC.to(device)\n",
        "else:\n",
        "  print(\"Using CPU!\")\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(X_torch_high)\n",
        "    #print(X_torch)\n",
        "    #print(y_pred)\n",
        "    #print(y_torch)\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_torch_highTC)\n",
        "    if epoch % 100 == 0: print(epoch, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "X_test_torch = torch.from_numpy(X_test_high).float()\n",
        "y_test_torch_highTC = torch.from_numpy(y_high_temp_test).float()\n",
        "\n",
        "print(\"Test set!\")\n",
        "\n",
        "if use_cuda:\n",
        "    print(\"Using GPU!\")\n",
        "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "    model.cuda()\n",
        "    X_test_torch = X_test_torch.to(device)\n",
        "    y_test_torch_highTC = y_test_torch_highTC.to(device)\n",
        "else:\n",
        "  print(\"Using CPU!\")\n",
        "\n",
        "test_preds = model(X_test_torch)\n",
        "testLoss = criterion(test_preds, y_test_torch_highTC)\n",
        "print(testLoss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU!\n",
            "0 0.16562584042549133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([17010])) that is different to the input size (torch.Size([3532, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 0.16534408926963806\n",
            "200 0.16521555185317993\n",
            "300 0.16513268649578094\n",
            "400 0.16508185863494873\n",
            "500 0.16504457592964172\n",
            "600 0.1650126576423645\n",
            "700 0.16499842703342438\n",
            "800 0.16498292982578278\n",
            "900 0.16499193012714386\n",
            "Test set!\n",
            "Using GPU!\n",
            "0.15887029469013214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([4252])) that is different to the input size (torch.Size([838, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro2FBI_Dtrzc",
        "colab_type": "code",
        "outputId": "e534036c-0060-46a6-bea0-d5ac0932ec2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_torch_highTC"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 1.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}